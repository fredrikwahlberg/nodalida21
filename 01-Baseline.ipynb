{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert os.path.exists('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/StClare_facs_danish.npz',\n",
       " 'data/SDHK_Latin.npz',\n",
       " 'data/StClare_facs_latin.npz',\n",
       " 'data/StClare_dipl_danish.npz',\n",
       " 'data/StClare_dipl_latin.npz',\n",
       " 'data/SDHK_Swedish.npz',\n",
       " 'data/Colonia.npz',\n",
       " 'data/SemEval2015.npz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataset(data_source_filename):\n",
    "    print(\"Loading %s... \" % data_source_filename.split(\"/\")[-1], end=\"\")\n",
    "    t = time.time()\n",
    "    dataset = dict()\n",
    "    with np.load(data_source_filename, allow_pickle=True) as source_file:\n",
    "        for key in source_file.keys():\n",
    "            dataset[key] = source_file[key].tolist()\n",
    "    print(\"done (%.1fs)\" % (time.time()-t), flush=True)\n",
    "    return dataset\n",
    "\n",
    "data_source_filenames = [os.path.join('data', fn) for fn in os.listdir('data')\n",
    "                        if os.path.isfile(os.path.join('data', fn)) and fn[-3:]=='npz']\n",
    "data_source_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading StClare_facs_danish.npz... done (0.0s)\n",
      " Classes in data: [1400 1425 1450 1475 1500 1525 1550 1575]\n",
      " Classes in train and dev: [1400 1425 1450 1475 1500 1525 1550 1575]\n",
      " Classes in test: [1400 1425 1450 1475 1500 1525 1550 1575]\n",
      "  MLE choice: 15.8%\n",
      "  Uniform: 12.5%\n",
      "  Weighted: 13.9%\n",
      "Saving StClare_facs_danish.npz... \n",
      "Loading SDHK_Latin.npz... done (1.4s)\n",
      " Classes in data: [1100 1125 1150 1175 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425\n",
      " 1450 1475 1500]\n",
      " Classes in train and dev: [1100 1125 1150 1175 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425\n",
      " 1450 1475 1500]\n",
      " Classes in test: [1125 1150 1175 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425 1450\n",
      " 1475 1500]\n",
      "  MLE choice: 26.3%\n",
      "  Uniform: 5.9%\n",
      "  Weighted: 17.7%\n",
      "Saving SDHK_Latin.npz... \n",
      "Loading StClare_facs_latin.npz... done (0.1s)\n",
      " Classes in data: [1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525]\n",
      " Classes in train and dev: [1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525]\n",
      " Classes in test: [1250 1275 1300 1325 1350 1375 1400 1425 1450 1475]\n",
      "  MLE choice: 19.7%\n",
      "  Uniform: 8.3%\n",
      "  Weighted: 14.7%\n",
      "Saving StClare_facs_latin.npz... \n",
      "Loading StClare_dipl_danish.npz... done (0.0s)\n",
      " Classes in data: [1400 1425 1450 1475 1500 1525 1550 1575]\n",
      " Classes in train and dev: [1400 1425 1450 1475 1500 1525 1550 1575]\n",
      " Classes in test: [1400 1425 1450 1475 1500 1525 1550 1575]\n",
      "  MLE choice: 15.8%\n",
      "  Uniform: 12.5%\n",
      "  Weighted: 13.9%\n",
      "Saving StClare_dipl_danish.npz... \n",
      "Loading StClare_dipl_latin.npz... done (0.1s)\n",
      " Classes in data: [1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525]\n",
      " Classes in train and dev: [1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525]\n",
      " Classes in test: [1250 1275 1300 1325 1350 1375 1400 1425 1450 1475]\n",
      "  MLE choice: 19.7%\n",
      "  Uniform: 8.3%\n",
      "  Weighted: 14.6%\n",
      "Saving StClare_dipl_latin.npz... \n",
      "Loading SDHK_Swedish.npz... done (0.6s)\n",
      " Classes in data: [1150 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500]\n",
      " Classes in train and dev: [1150 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500]\n",
      " Classes in test: [1200 1250 1275 1300 1325 1350 1375 1400 1425 1450 1500]\n",
      "  MLE choice: 69.0%\n",
      "  Uniform: 7.1%\n",
      "  Weighted: 54.2%\n",
      "Saving SDHK_Swedish.npz... \n",
      "Loading Colonia.npz... done (5.6s)\n",
      " Classes in data: [1500 1525 1550 1575 1600 1625 1650 1675 1700 1725 1750 1775 1800 1825\n",
      " 1850 1875 1900 1925]\n",
      " Classes in train and dev: [1500 1525 1550 1575 1600 1625 1650 1675 1725 1750 1775 1800 1825 1850\n",
      " 1875 1900 1925]\n",
      " Classes in test: [1525 1575 1625 1650 1700 1725 1750 1825 1850 1875 1900]\n",
      "  MLE choice: 26.3%\n",
      "  Uniform: 5.6%\n",
      "  Weighted: 11.9%\n",
      "Saving Colonia.npz... \n",
      "Loading SemEval2015.npz... done (0.2s)\n",
      " Classes in data: [1700 1725 1775 1800 1825 1850 1875 1900 1925 1950 1975 2000]\n",
      " Classes in train and dev: [1700 1725 1775 1800 1825 1850 1875 1900 1925 1950 1975 2000]\n",
      " Classes in test: [1700 1725 1775 1800 1825 1850 1875 1900 1925 1950 1975 2000]\n",
      "  MLE choice: 25.5%\n",
      "  Uniform: 8.3%\n",
      "  Weighted: 11.9%\n",
      "Saving SemEval2015.npz... \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#np.random.seed(42)\n",
    "\n",
    "for data_source_filename in data_source_filenames:\n",
    "    dataset = load_dataset(data_source_filename)\n",
    "    \n",
    "    results = {}\n",
    "    if 'baseline' in dataset.keys():\n",
    "        dataset.pop('baseline')\n",
    "        \n",
    "\n",
    "    y = np.asarray([np.mean(item['date']) if type(item['date']) is tuple else item['date'] for item in dataset['data']], np.int)\n",
    "    y = bin_width*(y//bin_width)\n",
    "\n",
    "\n",
    "    train, dev, test = dataset[\"folds\"][\"train\"], dataset[\"folds\"][\"val\"], dataset[\"folds\"][\"test\"]\n",
    "\n",
    "    print(\" Classes in data: %s\" % np.unique(y))\n",
    "    print(\" Classes in train and dev: %s\" % np.unique(y[train+dev]))        \n",
    "    print(\" Classes in test: %s\" % np.unique(y[test]))                \n",
    "\n",
    "    most_common, _ = Counter(y[train+dev]).most_common(1)[0]\n",
    "    mle_pred = [most_common]*len(test)\n",
    "    mle=100*sum(mle_pred==y[test])/len(test)\n",
    "\n",
    "    uniform_pred = np.random.choice(np.unique(y[dev+train]), size=len(test), replace=True)\n",
    "\n",
    "    uniform = 100*np.mean([np.sum(np.random.choice(np.unique(y[dev+train]), size=len(test), replace=True)==y[test])/len(test) for i in range(100000)])\n",
    "    #uniform = 100*np.sum(uniform_pred==y[test])/len(test)\n",
    "\n",
    "    weighted_pred = np.random.choice(y[train+dev], size=len(test), replace=False)\n",
    "    weighted = 100*np.mean([np.sum(np.random.choice(y[train+dev], size=len(test), replace=False)==y[test])/len(test) for i in range(100000)])\n",
    "    #weighted = 100*np.sum(weighted_pred==y[test])/len(test)\n",
    "\n",
    "    print(\"  MLE choice: %.1f%%\" % mle)\n",
    "    print(\"  Uniform: %.1f%%\" % uniform)\n",
    "    print(\"  Weighted: %.1f%%\" % weighted)\n",
    "\n",
    "    print(\" Saving %s... \" % data_source_filename.split(\"/\")[-1], end=\"\")\n",
    "\n",
    "    results[\"mle\"] = {\n",
    "        \"accuracy\":mle,\n",
    "        #\"y_pred\":mle_pred,\n",
    "        \"y_true\":y[test],        \n",
    "    }\n",
    "    results[\"uniform\"] = {\n",
    "        \"accuracy\":uniform,\n",
    "        #\"y_pred\":uniform_pred,\n",
    "        \"y_true\":y[test],        \n",
    "    }\n",
    "    results[\"weighted\"] = {\n",
    "        \"accuracy\":weighted,\n",
    "        #\"y_pred\":weighted_pred,\n",
    "        \"y_true\":y[test],        \n",
    "    }\n",
    "    print()\n",
    "    np.savez_compressed(data_source_filename, **dataset, baseline=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
